# Portfolio
Portfolio of independent projects

My name is Nate Slivka, and this Github repository is a collection of Python projects I've made on my own.

Projects included:
-DeclarationMaker (2023-2024): In 2023 and 2024 I was working as a legal assistant, and created a program to automate the generation of some documents I had to create regularly.
--Features: Parsed data extracted from my employer's database, generated Word documents formatted according to court formatting rules using that data, and manipulated large batches of PDF files to associate evidence with declarations.
--Status: Without data from the original database the parser doesn't really do anything, but the document generator and PDF manipulator code could be used if someone needed to generate a large number of repetitive documents.
--What did I Learn? I learned a lot about integrating my code into other peoples' programs and workflow from this project. I did not have access to any tools that would let me dig data out of my employer's database when I started, but I was able to jury-rig a solution using their terminal emulator's .txt dump feature, using a Python module to send key sequences to Windows to read through a large number of files very quickly. I then had to make sure my tool was parsing the correct data from the text dump, and generating correctly-formatted documents with the data from the database filled in to the correct locations. I submitted many documents generated using this tool to various courts in Washington State during my paralegal work, so I also had to be able to account for our lawyer and the court's formatting requirements, and accomodate any requests to change anything about the layout.

-ArsRete V1 (2023-2024): I built a basic neural network as a hobby project in my spare time in 2023 and 2024.
--Features: Original non-NN word generator tool, basic MLP network, generative adversarial network, and image processing/image recognition.
--Status: This runs, but it is an inefficient way to handle a neural network so it doesn't run well enough to do very much.
--What did I Learn? I learned about the basic underpinnings of a neural network here. The initial task I wanted to figure out neural networks to work on was OCR, to be able to account for documents that had been scanned in the wrong order; the word generation was initially a side project I put together in my spare time for fun. When I started working on this I had watched one short video on how neural networks worked and thought it sounded simple enough to implement; by the time I finished this stage I had a much clearer understanding of what neural networks do, how they work, and why my approach here wouldn't actually work and I needed to pick up more powerful tools.

-ArsRete V2 (2024): Starting around January of 2024 I had reached the limits of what my Numpy-based neural networks would do, and started exploring doing the same ideas with PyTorch.
--Features: Word generator tool, various GAN variants, and tools to analyze neural network training steps.
--Status: Runs, and works, but doesn't work that well.
--What did I learn? Having figured out how to make a neural network run in the first stage of this project my challenge here was making it actually work. I attempted to evaluate how well my neural network was working using several metrics, and was able to improve my outputs somewhat, but I also learned how difficult evaluating a neural network's outputs can be, and how difficult it is to work out what one is doing and how it works. I found and read papers on various peoples' attempts at doing clever, interesting variants on neural network architecture, some of which I understood and tried to implement, some of which I didn't really understand and tried to implement anyway. While working on this project I learned to try things, if I didn't see much of a change from something I was doing I learned to let go of my assumptions about what was going on and why, and just try something else.
